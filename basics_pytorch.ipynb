{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea2cfd92",
   "metadata": {},
   "source": [
    "# Introduction to Pytorch\n",
    "This notebook will provide a brief overview of PyTorch and how it is similar to Numpy. The goal of this notebook is to understand the basic data structures required to build Deep Learning models and train them.\n",
    "\n",
    "Why do we need PyTorch when we already have Numpy?\n",
    "Deep Learning involves performing similar operations like convolutions and multiplications repetitively. Thus there is a need to run the code on GPUs which can parallelize these operations over multiple cores - these devices are perfectly suitable for doing massive matrix operations and are much faster than CPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83fdefae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3339e31e",
   "metadata": {},
   "source": [
    "While NumPy with its various backends suits perfectly for doing calculus on CPU, it lacks the GPU computations support. And this is the first reason why we need Pytorch.\n",
    "\n",
    "The other reason is that Numpy is a genral purpose library. PyTorch ( or any other modern deep learning library ) has optimized code for many deep learning specific operations (e.g. Gradient calculations ) which are not present in Numpy.\n",
    "\n",
    "So, let's take a look at what are the data structures of Pytorch and how it provides us its cool features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c53447b",
   "metadata": {},
   "source": [
    "# Tensor Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b8091d",
   "metadata": {},
   "source": [
    "2 dimensional (rank2 tensor of zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe5b45d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(3,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3b0a08",
   "metadata": {},
   "source": [
    "Random rank -4 Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fede41a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.6465, 0.9161],\n",
       "          [0.3537, 0.0972]],\n",
       "\n",
       "         [[0.3524, 0.7389],\n",
       "          [0.6831, 0.7920]]],\n",
       "\n",
       "\n",
       "        [[[0.2586, 0.4030],\n",
       "          [0.2282, 0.4832]],\n",
       "\n",
       "         [[0.4378, 0.2899],\n",
       "          [0.7514, 0.9135]]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(2,2,2,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a89cf8",
   "metadata": {},
   "source": [
    "# Python/Numpy/Pytorch interoperability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedb0634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python List:  [1, 2]\n",
      "Numpy Array:  [1 2]\n",
      "Torch Tensor from List:  tensor([1, 2])\n",
      "Torch Tensor from Numpy Array:  tensor([1, 2], dtype=torch.int32)\n",
      "Torch Tensor from Numpy Array v2:  tensor([1, 2], dtype=torch.int32)\n",
      "Numpy Array from Torch Tensor:  [1 2]\n"
     ]
    }
   ],
   "source": [
    "#Simple List\n",
    "Python_list = [1,2]\n",
    "\n",
    "#create a numpy array from the python list\n",
    "numpy_array = np.array(Python_list)\n",
    "\n",
    "#create a torch tensor from the python list\n",
    "tensor_from_list = torch.tensor(Python_list)\n",
    "\n",
    "#create a torch Tensor from the numpy array\n",
    "tensor_from_numpy = torch.tensor(numpy_array)\n",
    "\n",
    "#aNOTHER WAY TO CREATE A TENSOR FROM A NUMPY ARRAY\n",
    "tensor_from_numpy_v2 = torch.from_numpy(numpy_array)\n",
    "\n",
    "#Convert torch tensor to numpy array\n",
    "array_from_tensor = tensor_from_numpy.numpy()\n",
    "\n",
    "print(\"Python List: \", Python_list)\n",
    "print(\"Numpy Array: \", numpy_array)\n",
    "print(\"Torch Tensor from List: \", tensor_from_list)\n",
    "print(\"Torch Tensor from Numpy Array: \", tensor_from_numpy)\n",
    "print(\"Torch Tensor from Numpy Array v2: \", tensor_from_numpy_v2)\n",
    "print(\"Numpy Array from Torch Tensor: \", array_from_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de35d80",
   "metadata": {},
   "source": [
    "# Difference between torch.Tensor and torch.from_numpy\n",
    "Pytorch aims to be effective library for computations. what does it mean? it means that pytorch avoids memory copying if it can:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d08d2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array:  [10  2]\n",
      "Tensor tensor([1, 2], dtype=torch.int32)\n",
      "Tensor v2 tensor([10,  2], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "numpy_array[0] = 10\n",
    "\n",
    "print('Array: ', numpy_array)\n",
    "print('Tensor', tensor_from_numpy)\n",
    "print('Tensor v2', tensor_from_numpy_v2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbdb12b",
   "metadata": {},
   "source": [
    "So, we have two different ways to create tensor from its Numpy counterpart- one copies memory and another shares the same underlying storage.It also works in the opposite way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1426e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor: tensor([1, 2], dtype=torch.int32)\n",
      "Array: [1 2]\n",
      "Tensor: tensor([11,  2], dtype=torch.int32)\n",
      "Array: [11  2]\n"
     ]
    }
   ],
   "source": [
    "array_from_tensor = tensor_from_numpy.numpy()\n",
    "print('Tensor:', tensor_from_numpy)\n",
    "print('Array:', array_from_tensor)\n",
    "\n",
    "tensor_from_numpy[0]= 11\n",
    "print('Tensor:', tensor_from_numpy)\n",
    "print('Array:', array_from_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1641ed1a",
   "metadata": {},
   "source": [
    "# Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92a1d626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor with default type: tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Tensor with float16 type: tensor([[0., 0.],\n",
      "        [0., 0.]], dtype=torch.float16)\n",
      "Tensor with int16 type: tensor([[0, 0],\n",
      "        [0, 0]], dtype=torch.int16)\n",
      "Tensor with bool type: tensor([[False, False],\n",
      "        [False, False]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.zeros(2,2)\n",
    "print('Tensor with default type:', tensor)\n",
    "tensor = torch.zeros(2,2, dtype=torch.float16)\n",
    "print('Tensor with float16 type:', tensor)\n",
    "tensor = torch.zeros(2,2, dtype=torch.int16)\n",
    "print('Tensor with int16 type:', tensor)\n",
    "tensor = torch.zeros(2,2, dtype=torch.bool)\n",
    "print('Tensor with bool type:', tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6362dbf8",
   "metadata": {},
   "source": [
    "# Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66d8340",
   "metadata": {},
   "source": [
    "Joining a list of tensors with torch.cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44ca9129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.zeros(3,2)\n",
    "b = torch.zeros(3,2)\n",
    "print(torch.cat((a,b), dim=0))\n",
    "print(torch.cat((a,b), dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc0582ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "[False False False False False False  True  True  True  True]\n",
      "tensor([6, 7, 8, 9])\n",
      "tensor([0, 1, 2, 3, 4, 0, 1, 2, 3, 4])\n",
      "tensor([0, 1, 2, 3, 4, 0, 1, 2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(start=0, end = 10)\n",
    "indices = np.arange(0,10)>5\n",
    "print(a)\n",
    "print(indices)\n",
    "print(a[indices])\n",
    "\n",
    "indices = torch.arange(start=0, end = 10)%5\n",
    "print(indices)\n",
    "print(a[indices])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77102ba9",
   "metadata": {},
   "source": [
    "what should we do if we havbe say rank2 tensor and want to select only some rows?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bff49c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6064, 0.2400, 0.6771],\n",
      "        [0.8170, 0.3314, 0.4365],\n",
      "        [0.4307, 0.5481, 0.0615],\n",
      "        [0.7245, 0.5518, 0.4984],\n",
      "        [0.8665, 0.3314, 0.9460]])\n",
      "tensor([[0.6064, 0.2400, 0.6771],\n",
      "        [0.4307, 0.5481, 0.0615],\n",
      "        [0.8665, 0.3314, 0.9460]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand((5,3))\n",
    "rows = torch.tensor([0,2,4])\n",
    "print(tensor)\n",
    "print(tensor[rows])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d42c4b3",
   "metadata": {},
   "source": [
    "# Tensor Shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d1e4d1",
   "metadata": {},
   "source": [
    "Reshaping a tensor is a frequently used operation. We can change the shape of a tensor without the memory copying overhead. There are two methods for that: reshape and view.\n",
    "\n",
    "The difference is the following:\n",
    "\n",
    "view tries to return the tensor, and it shares the same memory with the original tensor. In case, if it cannot reuse the same memory due to some reasons, it just fails.\n",
    "reshape always returns the tensor with the desired shape and tries to reuse the memory. If it cannot, it creates a copy.\n",
    "Let's see with the help of an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74b4cf71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pointer to data: 5124210689792\n",
      "Shape: torch.Size([2, 3, 4])\n",
      "Reshaped tensor - pointer to data: 5124210689792\n",
      "Reshaped tensor - shape: torch.Size([24])\n",
      "View tensor - pointer to data: 5124210689792\n",
      "View tensor - shape: torch.Size([3, 2, 4])\n",
      "Original stride:  (12, 4, 1)\n",
      "Reshaped stride:  (1,)\n",
      "Viewed stride:  (8, 4, 1)\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(2,3,4)\n",
    "print('Pointer to data:', tensor.data_ptr())\n",
    "print('Shape:', tensor.shape)\n",
    "\n",
    "reshaped = tensor.reshape(24)\n",
    "\n",
    "view = tensor.view(3,2,4)\n",
    "print('Reshaped tensor - pointer to data:', reshaped.data_ptr())\n",
    "print('Reshaped tensor - shape:', reshaped.shape)\n",
    "\n",
    "print('View tensor - pointer to data:', view.data_ptr())\n",
    "print('View tensor - shape:', view.shape)\n",
    "\n",
    "assert tensor.data_ptr() == view.data_ptr(), 'View and original tensor do not share the same data!'\n",
    "\n",
    "assert np.all(np.equal(tensor.numpy().flat, reshaped.numpy().flat))\n",
    "\n",
    "print('Original stride: ', tensor.stride())\n",
    "print('Reshaped stride: ', reshaped.stride())\n",
    "print('Viewed stride: ', view.stride())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1046f6a7",
   "metadata": {},
   "source": [
    "The basic rule about reshaping the tensor is definitely that you cannot change the total number of elements in it, so the product of all tensor's dimensions should always be the same. It gives us the ability to avoid specifying one dimension when reshaping the tensor - Pytorch can calculate it for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "76e99f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2, 4])\n",
      "torch.Size([3, 2, 4])\n",
      "torch.Size([3, 2, 4])\n"
     ]
    }
   ],
   "source": [
    "print(tensor.reshape(3, 2, 4).shape)\n",
    "print(tensor.reshape(3, 2, -1).shape)\n",
    "print(tensor.reshape(3, -1, 4).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca7d5c0",
   "metadata": {},
   "source": [
    "Alternative ways to view tensors - expand or expand_as.\n",
    "\n",
    "expand - requires the desired shape as an input\n",
    "expand_as - uses the shape of another tensor.\n",
    "These operaitions \"repeat\" tensor's values along the specified axes without actual copying the data.\n",
    "\n",
    "As the documentation says, expand\n",
    "\n",
    "returns a new view of the self tensor with singleton dimensions expanded to a larger size. Tensor can be also expanded to a larger number of dimensions, and the new ones will be appended at the front. For the new dimensions, the size cannot be set to -1.\n",
    "\n",
    "Use case:\n",
    "\n",
    "index multi-channel tensor with single-channel mask - imagine a color image with 3 channels (R, G and B) and binary mask for the area of interest on that image. We cannot index the image with this kind of mask directly since the dimensions are different, but we can use expand_as operation to create a view of the mask that has the same dimensions as the image we want to apply it to, but has not copied the da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d02443a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Create a black image\n",
    "image = torch.zeros(size=(3, 256, 256), dtype=torch.int)\n",
    "\n",
    "#Leave the borders and make the rest of the image Green\n",
    "image[1, 18:256 - 18, 18:256 - 18] = 255\n",
    "\n",
    "#Create a mask of the same size\n",
    "mask = torch.zeros(size=(256, 256), dtype=torch.bool)\n",
    "\n",
    "#Assuming the green area in the original image is the area of interest, change the mask to white for that area\n",
    "mask[18:256 - 18, 18:256 - 18] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bb2abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand the mask to have the same dimensions as the image\n",
    "expanded_mask = mask.unsqueeze(0).expand_as(image)\n",
    "print('Mask shape:', mask.shape)\n",
    "print('Expanded mask shape:', expanded_mask.shape)\n",
    "print('Image shape:', image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ee0ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the mask to the image\n",
    "# Only keep pixels where mask is True\n",
    "masked_image = image.clone()\n",
    "masked_image[~expanded_mask] = 0\n",
    "\n",
    "# Visualize the results\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.title('Original Image')\n",
    "plt.imshow(image.permute(1, 2, 0).numpy())\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.title('Mask')\n",
    "plt.imshow(mask.numpy(), cmap='gray')\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.title('Masked Image')\n",
    "plt.imshow(masked_image.permute(1, 2, 0).numpy())\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
